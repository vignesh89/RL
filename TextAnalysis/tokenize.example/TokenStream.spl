namespace tokenize.example;
/**
 * We have an input document spread across multiple lines; we want a stream 
 * of all the tokens in the document or document set.  Each output from the
 * text extract contains one token.
 */ 

composite TokenStream {
param 
expression<rstring> $inputFile: getSubmissionTimeValue("inputFile");
expression<rstring> $outFile: getSubmissionTimeValue("outFile","tokenstream.out");
expression<rstring> $tokenizer: getSubmissionTimeValue("tokenizer","multilingual");
expression<rstring> $stopWordsDict: getSubmissionTimeValue("stopwords","etc/punct.dict");
expression<rstring> $applicationDir: substring(getThisFileDir(),0,length(getThisFileDir())-1-length("tokenize.example"));

// Specify the langauge code to be used by the operator.
// For the list of languages supported, see http://pic.dhe.ibm.com/infocenter/bigins/v2r0/index.jsp?topic=%2Fcom.ibm.swg.im.infosphere.biginsights.text.doc%2Fdoc%2Ftext_analytics_languageware_support.html
expression<rstring> $langCode: "en";

graph 

stream<rstring inputDoc> Documents = FileSource() {
param file: $inputFile;
format:line;
}

//  Maybe our input is in fact one huge document, and we want all the tokens
// on one streams, but not in the same tuple.  Then we can use multiport mode.
stream<rstring atoken> TokenStream = com.ibm.streams.text.analytics::TextExtract(Documents) {
   param uncompiledModules: $applicationDir+"/etc/usetokenizer";
   tokenizer: $tokenizer;
   languageCode: $langCode;
   // This line is optional.  
   externalDictionary: "usetokenizer.StopwordsDict="+$applicationDir+"/"+$stopWordsDict;
   outputMode: "multiPort";
}

() as allTokensSink = FileSink(TokenStream) {
   param file: "tokenstream.out";
}
}
